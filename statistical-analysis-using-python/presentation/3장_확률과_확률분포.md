# 확률과 확률분포

1. 확률과 표본공간

    1. 기본 개념
        - 확률 : 어떤 사건이 일어날 가능성을 0과 1사이의 값으로 나타낸 것
        - 사상(event)  : 어떤 사건(또는 실험)의 결과가 여러가지일 때, 각각의 사건(또는 실험)의 결과를 말함
            - 단순사상 : 가장 단순한 형태의 사상으로 표본점이라고도 한다.
            - 복합사상 : 여러 사상이 합쳐져 단순사상으로 분해될 수 있는 상태의 사상
        - 표본공간 : 어떤 실험(또는 사건)의 결과로 얻어지는 모든 가능한 결과들의 집합으로 모든 표본점들의 집합이다.
    2. 확률의 조건
        - 표본 공간을 $S=\{s_1,~s_2,~\cdots\}$ 라고 하고 이 표본공간의 임의의 부분사상을 $A$라고 할 때 확률은 표본공간 $S$위에 정의되는 함수 $P(~\cdot~)$ 로서 아래 조건을 만족해야 한다.
            - $0\le P(A) \le1$
            - $P(S) = 1$
            - 서로 배반적인 부분사상 $A_1,~A_2,~\cdots$ 에 대해 
            $P(A_1\cup A_2 \cup\cdots)=P(A_1)+P(A_2)+\cdots$
            를 만족하며, 이 때 배반적이라 함은 $A_i \cap A_j = \text{\o},~i {=}\llap{/\,}j$ 을 의미한다.
    3. 확률에 관한 성질
        - 표본공간의 임의의 부분사상 $A$에 대해 $P(A)=1-P(A^c)$
        - $A\subset B$ 이면 $P(A) \le P(B)$
        - 임의의 두 사상 $A$와 $B$에 대해 $P(A \cup B)=P(A) + P(B)-P(A \cap B)$
    4. 결합확률
        - 결합확률 : 표본공간 안에서 일어나는 사건(또는 실험) 각각의 조합으로 정의될 수 있는 확률로 두 개 이상의 서로 다른 두 사건(또는 실험)이 동시에 일어나는 확률을 의미한다.
        - 주변확률 : 개별 사건(또는 실험) 각각에 대한 확률을 말하며, 결합 사건(또는 실험)들의 확률의 합으로 나타낼 수 있다.
    5. 조건부확률
        - 어떤 사건 $A$가 일어났을 때 사건 $B$가 일어날 확률을 말하며, $A$가 주어져 있을 때 사건 $B$의 조건부확률 $P(B|A)$은 아래 조건을 만족해야 한다.
            - 표본공간 $S$의 임의의 부분사상 $B$에 대해 $0 \le P(B|A) \le 1$
            - $P(S|A)=1$
            - 서로 배반적인 부분사상 $B_1,~B_2,~\cdots$에 대해 $P(~B_1 \cup B_2 \cup \cdots |~A~)=P(B_1 | A) + P(B_2 | A) + \cdots$
    6. 사상 간의 독립
        - 독립 : 한 사건(또는 실험)의 발생이 다른 사건의 발생 확률에 영향을 주지 않는 경우를 말한다(반대의 개념으로 종속이 있다).
        - 두 사건 $A$와 $B$가 서로 독립인 경우 아래가 성립한다.
            - $P(B~|~A)=P(B)$ 이고 동시에 $P(A~|~B)=P(A)$
            - $P(A \cap B) = P(A)P(B)$
            - $P(B~|~A) = \cfrac{P(A \cap B)}{P(A)}=\cfrac{P(A)P(B)}{P(A)}=P(B)$
        - [https://blog.naver.com/tmdwls379/222049985192](https://blog.naver.com/tmdwls379/222049985192)
2. 확률변수의 분류

    1. 확률변수
        - 확률변수는 출력이 가능한 여러 값 중 특정 값을 갖을 확률을 고려할 수 있다라는 차원에서 확률변수라고 부른다.
        - 확률변수가 취할 수 있는 값이 여럿이므로 어떤 분포를 따른다고 할 수 있으며, 이 때의 분포를 확률 분포라고 한다.
    2. 확률변수의 종류
        - 범주형변수
            - 명목변수
            - 순위변수 : 순서관계를 나타내는 척도
        - 연속형변수(어떠한 통계적 분석도 가능)
            - 구간변수 : 순위를 나타내지만 순서 사이의 간격이 동일한 척도
            - 비율변수 : 나이, 체중, 신장 등과 같이 크기 차이, 속성간 비율 등 **비율계산이 가능한** 척도
            
            ※ 주의할 점은 명목변수의 자료는 분류시키는 것만 가능하나, 비율변수는 구간변수로 전환 또는 순위를 매길 수도 있다.
3. 확률변수와 확률분포

    1. 확률분포
        - 함수 $X$를 확률변수라고 할 때, $X$가 취할 수 있는 범위 내에서의 각 값에 대해 확률을 갖게 되는데 이를 확률분포라고 부르고 $f(x)$로 표현한다.
    2. 확률변수 형태별 특징
        - 확률변수 $X$가 이산형인 경우
            - $f(x) \geq 0$, 모든 $x$에서
            - $\displaystyle\sum_{모든~x}f(x)=1$
        - 확률변수 $X$가 연속형인 경우
            - $f(x) \geq 0$, 모든 $x$에서
            - $\int f(x)dx=1$
            
            ※ 확률변수 $X$가 이산형인 경우 $X$가 취하는 값에서의 확률들의 분포가 곧 확률분포가 된다.
4. 기댓값

    1. 기댓값이란
        - “모집단의 평균 = 확률변수 $X$의 평균” 이라고 할 때, 확률변수 $X$의 기댓값은 아래와 같다.
            - $E(X)=\displaystyle\sum_{모든~x}x ~\cdot~f(x)$
    2. 모집단의 분산
        - 표본값 $\{x_1,~x_2,~\cdots,~x_n\}$ 에 대한 표본분산은 $s^2=\cfrac{\sum(x_i-\bar{x})^2}{n-1}$ 으로 편차의 제곱평균을 의미하게 된다.
        - 모집단의 분산 역시 편차 제곱의 평균으로 아래와 같이 나타낼 수 있다.
            - $\sigma^2=Var(X)=E[(X-\mu)^2]=\displaystyle\sum_{모든~x}(x-\mu)^2f(x)$
5. 베르누이분포

    1. 베르누이분포
        - 어떤 조사나 실험이 두 가지의 결과만 가능한 경우일 때 그 확률변수는 베르누이분포를 따른다고 한다.
        - 이산형변수에 적용하므로 베르누이분포에서는 $f(x)$ 그 자체가 확률을 나타낸다.
        - 베르누이분포의 형태는 아래와 같다.
            - $f(x)=p^x(1-p)^{1-x},~x=0,~1$
    2. 베르누이분포를 따르는 확률변수 $X$의 기댓값
        - $\mu=E(x)=a(1-p)+b(p)=p$
        단, $a$와 $b$는 조사 또는 실험의 결과값으로서 $a=0, ~b=1$
    3. 베르누이분포를 따르는 확류변수 $X$의 분산
        - $\sigma^2=Var(X)=E[(X-\mu)^2]=(a-p)^2(1-p)+(b-p)^2p=p(1-p)$
        단, $a$와 $b$는 조사 또는 실험의 결과값으로서 $a=0, ~b=1$
6. 정규분포

    1. 정규분포
        - 정규분포란, 평균을 중심으로 좌우가 대칭인 형태를 갖는 분포를 말한다.
        - 연속형변수에 적용하므로 정규분포에서는 $f(x)$ 그 자체가 확률을 나타내지 않으며, 정규분포에서의 확률은 곡선의 아랫부분의 면적을 구하는 것과 같다.
    2. 표준정규분포
        - 평균이 $0$이고 표준편차가 $1$인 정규분포
        - 특정 자료가 정규분포를 따를 때, 보다 계산 또는 비교가 용이하도록 하기 위해 평균과 표준편차를 일치시켜(표준화) 표준정규분포를 따르도록할 수 있다.
            - 표준화 : $Z=\cfrac{X-\mu}{\sigma}$
            - $Z$를 표준정규분포 확률변수라고 부른다.
            - 그 밖에도 표준화는 자료의 단위가 상이할 때 단위를 통일하여 쉽게 비교하도록 하는데 사용할 수 있다.
7. 결합분포와 상관계수

    1. 결합분포
        - 두 개의 변수에 대해 $(X,Y)$의 분포를 $f_{XY}(x, y)$로 나타낼 때 이를 결합확률분포라고 부른다.
        - 이 때 두 개의 변수 $X,~Y$ 각각의 확률변수의 확률분포를 $f_X(x),~f_Y(y)$로 나타낼 수 있는데, 각각을 주변확률분포라고 부른다.
        - 또한, $X$가 주어졌을 경우 $Y$의 분포를 $f_{(Y~|~X)}(y~|~x=a)$로 표현하며, 이를 조건부확률분포라고 부른다.
        - 단, 두 변수가 연속적인 변수인 경우 두 확률변수의 결합분포를 찾는것이 매우 어려울 수 있다. 따라서 각 변수를 적당한 구간으로 나누어 범주형 변수(등간변수)로 전환한 후 결합분포를 찾는것이 바람직하다.
    2. 두 확률변수의 독립
        - 두 확률변수 $X$와 $Y$가 독립인 경우  아래가 성립한다.
            - $f_{XY}(x,y)=f_X(x)f_Y(y)$
    3. 공분산
        - 공분산이란, 두 확률변수 각각의 편차를 서로 곱한 것들에 대한 평균(기댓값)을 말한다.
            - $Cov(X,Y)=E[(X-\mu_{X})(Y-\mu_{Y})]$
            $=\displaystyle\sum_{i}\displaystyle\sum_{j}(x_i-\mu_X)(y_j-\mu_Y)f_{XY}(x,y)$
        - 공분산으로 $X$와 $Y$의 **관계**와 그 **정도**를 알 수 있다.
        - 단, 공분산은 각 확률변수의 측정 단위가 다를 경우 그 크기가 공분산의 크기에 영향을 주므로 두 확률변수의 관계의 정도를 정확하게 가늠하기 어렵다.
    4. 상관관계
        - 상관계수란, 공분산의 단위를 제거하여 나타낸 두 확률변수의 관계지표
            - $\rho=Corr(X,Y)=\cfrac{Cov(X,Y)}{\sqrt{Var(X)}\sqrt{Var(Y)}}$
            - $-1 \le \rho \le 1$
        - 상관계수에 영향을 미치는 요인
            - 자료의 범위를 어떻게 제한할지
            - 집단을 어떻게 결합하는지
    5. 파이 상관계수
        - 피어슨 상관계수가 연속적인 변수들에 대한 직선적 상관관계를 나타내는 상관계수라면, 파이 상관계수는 dummy 변수에 대한 상관관계를 나타내기에 적절한 상관계수가 될 수 있다.
            - $\phi=\cfrac{P_C-P_XP_Y}{\sqrt{P_X(1-P_X)P_Y(1-P_Y)}}$
            - $P_C=~(X=1,~Y=1)$인 사람의 비율
            - $P_X=~(X=1)$인 사람의 비율
            - $P_Y=~(Y=1)$인 사람의 비율
8. 기댓값과 분산의 응용

    1. 기댓값
        - 상수 c의 기댓값은 c이다.
            - $E(c)=c$
        - 확률변수 $X$에 $a$를 곱한 것의 기댓값은 $X$의 기댓값에 $a$를 곱한 것과 같다.
            - $E(aX)=a\mu_X$
        - 확률변수 $X에 a$를 곱하여 $b$를 더한 것의 기댓값은 $X$의 기댓값에 $a$를 곱하여 $b$를 더한 것과 같다.
            - $E(aX+b)=aE(X)+b$
    2. 분산
        - 확률변수 $X$의 분산은 다음과 같이 정의한다.
            - $Var(X)=\sigma_X^2$
        - 확률변수 $X$의 분산은 $X^2$의 기댓값에서 $X$의 기댓값 제곱을 뺀 것과 같다.
            - $Var(X)=E(X^2)-\mu_X^2$
        - 상수 c의 분산은 0이다.
            - $Var(c)=0$
        - 확률변수 $X$에 $a$를 곱하여 $b$를 더한 것의 분산은 $X$의 분산에 $a^2$을 곱한 것과 같다.
            - $Var(aX+b)=a^2\sigma_X^2$
    3. 두 확률변수에 대하여
        - 확률변수 $X$ $X$$Y$의 합에 대한 기댓값은 각각의 기댓값 합과 같다.
            - $E(X+Y)=\mu_X+\mu_Y$
        - 확률변수 $X$에 $a$를 곱한 것과 확률변수 $Y$에 $b$를 곱한 것의 합에 대한 기댓값은 $X$의 기댓값에 $a$를 곱한 것과 $Y$의 기댓값에 $b$를 곱한 것의 합과 같다.
            - $E(aX+bY)=a\mu_X+b\mu_Y$
        - 확률변수 $X$와 $Y$의 공분산은 다음과 같다.
            - $Cov(X,Y)=E[(X-\mu_X)(Y-\mu_Y)]=\sigma_{XY}$
            - $Cov(X,Y)=E(XY)-E(X)E(Y)$
        - 확률변수 $X$에 $a$를 곱한 것과 확률변수 $Y$에 $b$를 곱한 것의 공분산은 두 변수 $X$와 $Y$의 공분산에 $ab$를 곱한 것과 같다.
            - $Cov(aX, bY)=abCov(X,Y)$
        - 확률변수 $X$와 확률변수 $Y$의 합에 대한 분산은 각 확률변수 분산의 합과 두 확률변수의 공분산에 2를 곱한 것의 합과 같다.
            - $Var(X+Y)=Var(X)+Var(Y)+2Cov(X, Y)$
        - 두 확률변수 $X$와 $Y$가 서로 독립이면 두 변수의 공분산은 0이 되므로 아래가 성립한다.
            - $Var(X+Y)=Var(X)+Var(Y)$
            - 단, 공분산이 0이라고 해서 $X$와 $Y$가 독립인 것은 아니다.
        - 확률변수 $(aX+bY)$에 대한 분산은 다음과 같다.
            - $Var(aX+bY)=a^2Var(X)+b^2Var(Y)+2abCov(X,Y)$
        - 확률변수 $(aX+bY+cZ)$에 대한 분산은 다음과 같다.
            - $Var(aX+bY+cZ)=a^2Var(X)+b^2Var(Y)+c^2Var(Z)+2abCov(X,Y)+2acCov(X,Z)+2bcCov(Y,Z)$